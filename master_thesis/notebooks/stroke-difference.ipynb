{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from master_thesis.classification_models import VectorModel, BaseModel\n",
    "\n",
    "MAT_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/Stroke-difference/mean_ed.mat\"\n",
    "K_FOLDS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting matlab matrix to numpy array\n",
    "The resulting array shoul be 400x130, representing 400 ROIs and 130 subjects (of which the first 26 are controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the mat file: (400, 130)\n"
     ]
    }
   ],
   "source": [
    "n_nodes = 400\n",
    "n_total = 130\n",
    "n_control = 26\n",
    "\n",
    "sd = loadmat(MAT_PATH)[\"EDtocontrol_before\"]\n",
    "print(f\"Shape of the mat file: {sd.shape}\")\n",
    "\n",
    "assert sd.shape == (n_nodes, n_total), \"Shape of the mat file is not as expected\"\n",
    "\n",
    "control_np = sd[:, :n_control].T\n",
    "stroke_np = sd[:, n_control:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sd.T\n",
    "y = np.array([0] * n_control + [1] * (n_total - n_control), dtype=np.int32)\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.seed(42)\n",
    "shuffle_index = np.random.permutation(n_total)\n",
    "X, y = X[shuffle_index], y[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-validation: 100%|██████████| 10/10 [00:00<00:00, 10.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define accumulator lists\n",
    "y_gold_train_acc, y_hat_train_acc = [], []\n",
    "y_gold_test_acc, y_hat_test_acc = [], []\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=3346)\n",
    "for i, (train_index, test_index) in tqdm(enumerate(kfold.split(X)), total=K_FOLDS, desc=\"Cross-validation\"):\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "    # Train model\n",
    "    model = VectorModel()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_train_acc.append(y_hat_train)\n",
    "    y_gold_train_acc.append(y_train)\n",
    "\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    y_hat_test_acc.append(y_hat_test)\n",
    "    y_gold_test_acc.append(y_test)\n",
    "\n",
    "# Concatenate lists\n",
    "y_hat_train = np.concatenate(y_hat_train_acc)\n",
    "y_gold_train = np.concatenate(y_gold_train_acc)\n",
    "\n",
    "y_hat_test = np.concatenate(y_hat_test_acc)\n",
    "y_gold_test = np.concatenate(y_gold_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model on train data ===\n",
      "Accuracy:  1.00\n",
      "Recall:    1.00\n",
      "Precision: 1.00\n",
      "f1 score:  1.00\n",
      "AUC score: 1.00\n",
      "\n",
      "=== Evaluating model on test data ====\n",
      "Accuracy:  0.80\n",
      "Recall:    1.00\n",
      "Precision: 0.80\n",
      "f1 score:  0.89\n",
      "AUC score: 0.50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate classification\n",
    "print(\"=== Evaluating model on train data ===\")\n",
    "print(BaseModel.evaluate(y_gold_train, y_hat_train, save_path=\"ltp_cm_train.png\"))\n",
    "\n",
    "print(\"=== Evaluating model on test data ====\")\n",
    "print(BaseModel.evaluate(y_gold_test, y_hat_test, save_path=\"ltp_cm_test.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_np_feature_0 = control_np[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_np_feature_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sano",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
