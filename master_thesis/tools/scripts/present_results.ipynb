{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RESULTS_SUMMARY_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Results/20240410-094852_GAT/results_summary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>combined_auc</th>\n",
       "      <th>mean_auc</th>\n",
       "      <th>std_auc</th>\n",
       "      <th>pval_auc</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>mean_precision</th>\n",
       "      <th>std_precision</th>\n",
       "      <th>mean_recall</th>\n",
       "      <th>std_recall</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>std_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stroke_RCC</td>\n",
       "      <td>GAT</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>0.613825</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>0.583586</td>\n",
       "      <td>0.100104</td>\n",
       "      <td>0.901893</td>\n",
       "      <td>0.088624</td>\n",
       "      <td>0.587571</td>\n",
       "      <td>0.148771</td>\n",
       "      <td>0.694898</td>\n",
       "      <td>0.098224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stroke_RCC</td>\n",
       "      <td>LTP</td>\n",
       "      <td>0.684649</td>\n",
       "      <td>0.690006</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.697172</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.922762</td>\n",
       "      <td>0.052296</td>\n",
       "      <td>0.704138</td>\n",
       "      <td>0.075732</td>\n",
       "      <td>0.794712</td>\n",
       "      <td>0.044345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stroke_GC</td>\n",
       "      <td>GAT</td>\n",
       "      <td>0.618427</td>\n",
       "      <td>0.641560</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.645169</td>\n",
       "      <td>0.132119</td>\n",
       "      <td>0.902823</td>\n",
       "      <td>0.056232</td>\n",
       "      <td>0.657406</td>\n",
       "      <td>0.189305</td>\n",
       "      <td>0.741673</td>\n",
       "      <td>0.130760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stroke_GC</td>\n",
       "      <td>LTP</td>\n",
       "      <td>0.711387</td>\n",
       "      <td>0.724048</td>\n",
       "      <td>0.118574</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.792126</td>\n",
       "      <td>0.137667</td>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.045141</td>\n",
       "      <td>0.823334</td>\n",
       "      <td>0.149278</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.103994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset model  combined_auc  mean_auc   std_auc  pval_auc  \\\n",
       "0  stroke_RCC   GAT      0.587891  0.613825  0.125134  0.011634   \n",
       "1  stroke_RCC   LTP      0.684649  0.690006  0.065190  0.000005   \n",
       "2   stroke_GC   GAT      0.618427  0.641560  0.089358  0.000520   \n",
       "3   stroke_GC   LTP      0.711387  0.724048  0.118574  0.000153   \n",
       "\n",
       "   mean_accuracy  std_accuracy  mean_precision  std_precision  mean_recall  \\\n",
       "0       0.583586      0.100104        0.901893       0.088624     0.587571   \n",
       "1       0.697172      0.055152        0.922762       0.052296     0.704138   \n",
       "2       0.645169      0.132119        0.902823       0.056232     0.657406   \n",
       "3       0.792126      0.137667        0.912052       0.045141     0.823334   \n",
       "\n",
       "   std_recall   mean_f1    std_f1  \n",
       "0    0.148771  0.694898  0.098224  \n",
       "1    0.075732  0.794712  0.044345  \n",
       "2    0.189305  0.741673  0.130760  \n",
       "3    0.149278  0.860577  0.103994  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv(RESULTS_SUMMARY_PATH)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all[df_all[\"model\"] == \"GAT\"].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(df: pd.DataFrame, dataset: str, metric: str) -> float:\n",
    "    return df[df[\"dataset\"] == dataset][metric].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ltp = \\\n",
    "f\"\"\"\n",
    "AUC score (combined)    & {get_value(df, \"stroke_RCC\", \"combined_auc\"):.4f} & {get_value(df, \"stroke_GC\", \"combined_auc\"):.4f}  \\\\\\\\\n",
    "AUC score (folds)       & ${get_value(df, \"stroke_RCC\", \"mean_auc\"):.4f} \\pm {get_value(df, \"stroke_RCC\", \"std_auc\"):.4f}$ & ${get_value(df, \"stroke_GC\", \"mean_auc\"):.4f} \\pm {get_value(df, \"stroke_GC\", \"std_auc\"):.4f}$  \\\\\\\\\n",
    "Accuracy                & ${get_value(df, \"stroke_RCC\", \"mean_accuracy\"):.4f} \\pm {get_value(df, \"stroke_RCC\", \"std_accuracy\"):.4f}$ & ${get_value(df, \"stroke_GC\", \"mean_accuracy\"):.4f} \\pm {get_value(df, \"stroke_GC\", \"std_accuracy\"):.4f}$  \\\\\\\\\n",
    "Precision               & ${get_value(df, \"stroke_RCC\", \"mean_precision\"):.4f} \\pm {get_value(df, \"stroke_RCC\", \"std_precision\"):.4f}$ & ${get_value(df, \"stroke_GC\", \"mean_precision\"):.4f} \\pm {get_value(df, \"stroke_GC\", \"std_precision\"):.4f}$  \\\\\\\\\n",
    "Recall                  & ${get_value(df, \"stroke_RCC\", \"mean_recall\"):.4f} \\pm {get_value(df, \"stroke_RCC\", \"std_recall\"):.4f}$ & ${get_value(df, \"stroke_GC\", \"mean_recall\"):.4f} \\pm {get_value(df, \"stroke_GC\", \"std_recall\"):.4f}$  \\\\\\\\\n",
    "f1 score                & ${get_value(df, \"stroke_RCC\", \"mean_f1\"):.4f} \\pm {get_value(df, \"stroke_RCC\", \"std_f1\"):.4f}$ & ${get_value(df, \"stroke_GC\", \"mean_f1\"):.4f} \\pm {get_value(df, \"stroke_GC\", \"std_f1\"):.4f}$  \\\\\\\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC score (combined)    & 0.5879 & 0.6184  \\\\\n",
      "AUC score (folds)       & $0.6138 \\pm 0.1251$ & $0.6416 \\pm 0.0894$  \\\\\n",
      "Accuracy                & $0.5836 \\pm 0.1001$ & $0.6452 \\pm 0.1321$  \\\\\n",
      "Precision               & $0.9019 \\pm 0.0886$ & $0.9028 \\pm 0.0562$  \\\\\n",
      "Recall                  & $0.5876 \\pm 0.1488$ & $0.6574 \\pm 0.1893$  \\\\\n",
      "f1 score                & $0.6949 \\pm 0.0982$ & $0.7417 \\pm 0.1308$  \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(table_ltp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sano",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
