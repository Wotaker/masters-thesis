{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from master_thesis.utils import LOGLEVEL_MAP\n",
    "from master_thesis.classification_models import *\n",
    "from master_thesis.tools.data import  load_np_data, Preprocessing\n",
    "from master_thesis.tools.plots import plot_sample_networks, plot_weight_histogram\n",
    "\n",
    "logging.basicConfig(level=LOGLEVEL_MAP[\"INFO\"])\n",
    "\n",
    "SEED = 42\n",
    "K_FOLDS = 10\n",
    "\n",
    "# === Scale Free Synthetic Dataset ===\n",
    "# NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/Synthetic/ScaleFreeBias/networks\"\n",
    "# NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/Synthetic/ScaleFreeEasy/networks\"\n",
    "\n",
    "# === Real World Stroke Split Dataset ===\n",
    "NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/NeuroFlicksFC/networks\"\n",
    "# NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/NeuroFlicksGC/networks\"\n",
    "# NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/NeuroFlicksRCC/networks\"\n",
    "# NETWORKS_DIR_PATH = \"/Users/wciezobka/sano/projects/masters-thesis/Datasets/NeuroFlicksUnidirRCC/networks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = Preprocessing(undirected=True, connection_weight_threshold=(0.5, 0.999), seed=SEED)(*load_np_data(NETWORKS_DIR_PATH, channel=0))\n",
    "X, y = Preprocessing(undirected=True, connection_weight_threshold=(0.5, 0.999), shuffle=False)(*load_np_data(NETWORKS_DIR_PATH))\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plot_weight_histogram(X[idx], y[idx])\n",
    "print(f\"Ratio of edges to the full graph: {len(X[idx].edges) / (50 * 99)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot sample class members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample networks\n",
    "plot_sample_networks(X, y, rows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedd networks (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph2vec = Graph2Vec(dimensions=32, wl_iterations=2, epochs=200, seed=SEED, workers=1)\n",
    "# graph2vec.fit(X)\n",
    "# X = graph2vec.get_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe through the LDP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accumulator lists\n",
    "y_gold_train_acc, y_hat_train_acc = [], []\n",
    "y_gold_test_acc, y_hat_test_acc = [], []\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "for i, (train_index, test_index) in tqdm(enumerate(kfold.split(X)), total=K_FOLDS, desc=\"Cross-validation\"):\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "    # Train model (Graph2Vec)\n",
    "    # model = VectorModel()\n",
    "    # model.fit(X_train, y_train)\n",
    "\n",
    "    # Train model (LTP)\n",
    "    model = LTPModel(log_degree=True)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_hat_train = model.predict(X_train)\n",
    "    y_hat_train_acc.append(y_hat_train)\n",
    "    y_gold_train_acc.append(y_train)\n",
    "\n",
    "    y_hat_test = model.predict(X_test)\n",
    "    y_hat_test_acc.append(y_hat_test)\n",
    "    y_gold_test_acc.append(y_test)\n",
    "\n",
    "# Concatenate lists\n",
    "y_hat_train = np.concatenate(y_hat_train_acc)\n",
    "y_gold_train = np.concatenate(y_gold_train_acc)\n",
    "\n",
    "y_hat_test = np.concatenate(y_hat_test_acc)\n",
    "y_gold_test = np.concatenate(y_gold_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classification\n",
    "print(\"=== Evaluating model on train data ===\")\n",
    "print(BaseModel.evaluate(y_gold_train, y_hat_train, save_path=\"ltp_cm_train.png\"))\n",
    "\n",
    "print(\"=== Evaluating model on test data ====\")\n",
    "print(BaseModel.evaluate(y_gold_test, y_hat_test, save_path=\"ltp_cm_test.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "holdout_size = 0.2\n",
    "holdout_size = int(holdout_size * len(X))\n",
    "\n",
    "# Shuffle data\n",
    "idx = np.arange(len(X))\n",
    "np.random.shuffle(idx)\n",
    "X = [X[i] for i in idx]\n",
    "y = [y[i] for i in idx]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test = X[:-holdout_size], X[-holdout_size:]\n",
    "y_train, y_test = y[:-holdout_size], y[-holdout_size:]\n",
    "\n",
    "# Train model\n",
    "model = GCNModel(learning_rate=0.005, epochs=100, print_every=20, ldp_features=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Evaluating model on train data ===\")\n",
    "y_hat_train = model.predict(X_train)\n",
    "print(BaseModel.evaluate(np.array(y_train), y_hat_train, plot_cm=True))\n",
    "\n",
    "print(\"=== Evaluating model on test data ====\")\n",
    "y_hat_test = model.predict(X_test)\n",
    "print(BaseModel.evaluate(y_test, y_hat_test, plot_cm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sano",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
